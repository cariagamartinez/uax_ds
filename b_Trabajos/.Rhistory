Actividad_Fisica + Fumador, data = datos)
# Resumen del modelo
summary(modelo)
# 4. Evaluación del Modelo
# Predicción en los datos de entrenamiento
predicciones <- predict(modelo, newdata = datos)
# Cálculo del error
error_rmse <- sqrt(mean((datos$Riesgo_Cardiovascular - predicciones)^2))
cat("Error RMSE del modelo:", error_rmse, "\n")
# Cargamos las librerías necesarias
library(tidyverse)  # Para manipulación de datos y visualización
library(caret)      # Para evaluación del modelo
# 1. Lectura del dataset
datos <- read.csv("Session_Workshop/dataset_session_biomedicina.csv")
# Exploración inicial del dataset
str(datos)  # Estructura del dataset
summary(datos)  # Resumen estadístico de las variables
# 2. Análisis Exploratorio de Datos (EDA)
# Distribución de la variable objetivo (Riesgo_Cardiovascular)
hist(datos$Riesgo_Cardiovascular,
main = "Distribución del Riesgo Cardiovascular",
xlab = "Riesgo Cardiovascular",
ylab = "Frecuencia",
col = "skyblue",
border = "black")
# Relación entre Edad e IMC con el Riesgo Cardiovascular
plot(datos$Edad, datos$Riesgo_Cardiovascular, main = "Edad vs Riesgo Cardiovascular",
xlab = "Edad", ylab = "Riesgo Cardiovascular", pch = 19, col = "blue")
plot(datos$IMC, datos$Riesgo_Cardiovascular, main = "IMC vs Riesgo Cardiovascular",
xlab = "IMC", ylab = "Riesgo Cardiovascular", pch = 19, col = "red")
# Conversión de variables categóricas a factores para el modelo
datos$Actividad_Fisica <- as.factor(datos$Actividad_Fisica)
datos$Fumador <- as.factor(datos$Fumador)
# Separación de los datos en conjuntos de entrenamiento y prueba
set.seed(123)
index <- createDataPartition(datos$Riesgo_Cardiovascular, p = 0.7, list = FALSE)
train_data <- datos[index, ]
test_data <- datos[-index, ]
# 3. Generación de un modelo de regresión lineal
# Definimos el modelo lineal para predecir el Riesgo Cardiovascular
modelo <- lm(Riesgo_Cardiovascular ~ Edad + IMC + Nivel_Glucosa + Nivel_Colesterol +
Actividad_Fisica + Fumador, data = train_data)
# Resumen del modelo
summary(modelo)
# Utilizamos plot(modelo) para generar los gráficos de diagnóstico del modelo
par(mfrow = c(2, 2))  # Configura el espacio de gráficos para mostrar 4 gráficos: 2 filas x 2 columnas
plot(modelo)
par(mfrow = c(1, 1))  # Restablece la configuración de gráficos
# 4. Evaluación del modelo
# Predicción en los datos de entrenamiento
predicciones <- predict(modelo, newdata = test_data)
# Cálculo del error
rmse <- sqrt(mean((test_data$Riesgo_Cardiovascular - predicciones)^2))
cat("Error RMSE del modelo:", rmse, "\n")
# 5. Interpretación y conclusión
# Basándonos en los resultados del modelo, observamos que:
# - La Edad, el Nivel de Glucosa y el Nivel de Colesterol parecen tener un efecto positivo en el Riesgo Cardiovascular,
#   mientras que el IMC tiene un efecto negativo, lo cual podría requerir un análisis más profundo.
# - Las variables categóricas como el nivel de actividad física y el hábito de fumar también pueden influir en el riesgo aunque no de
# manera estadísticamente significativa así que habría que
# Cargar librerías necesarias
library(tidyverse)   # Para manipulación de datos
library(caret)       # Para modelos y validación cruzada
library(class)       # Para K-NN
# 1. Lectura del dataset
# Asegúrate de guardar el archivo como 'Alzheimer_dataset.csv' en el mismo directorio que el script.
datos <- read.csv("Alzheimer_dataset.csv", sep = ";")
datos <- read.csv("T2/Alzheimer_dataset.csv", sep = ";")
# Exploración inicial
str(datos)  # Estructura del dataset
summary(datos)  # Resumen estadístico
# 2. Análisis exploratorio (EDA)
# Comprobar distribución de la variable objetivo (Target)
table(datos$Target)
barplot(table(datos$Target), main = "Distribución de la Variable Target",
xlab = "Clase", ylab = "Frecuencia", col = c("skyblue", "orange"))
# Visualización de correlaciones entre variables numéricas
numericas <- select(datos, where(is.numeric))
correlaciones <- cor(numericas)
corrplot::corrplot(correlaciones, method = "circle", main = "Matriz de Correlación")
# Visualizar la distribución de algunas variables
ggplot(datos, aes(x = Edad, fill = as.factor(Target))) +
geom_density(alpha = 0.6) +
labs(title = "Distribución de Edad por Clase", x = "Edad", fill = "Clase")
# Visualizar la distribución de algunas variables
# Edad por clases de Target
hist(datos$Edad[datos$Target == 0], breaks = 15, col = "lightblue", main = "Distribución de Edad (Clase 0)",
xlab = "Edad", ylab = "Frecuencia")
hist(datos$Edad[datos$Target == 1], breaks = 15, col = "pink", main = "Distribución de Edad (Clase 1)",
xlab = "Edad", ylab = "Frecuencia")
View(datos)
# Boxplot para una variable como ejemplo
boxplot(Edad ~ Target, data = datos, main = "Boxplot de Edad por Clase",
xlab = "Clase", ylab = "Edad", col = c("lightblue", "pink"))
#Visualización avanzada con la librería GGPLOT2
ggplot(datos, aes(x = Edad, fill = as.factor(Target))) +
geom_density(alpha = 0.6) +
labs(title = "Distribución de Edad por Clase", x = "Edad", fill = "Clase")
boxplot(datos$Edad, main = "Boxplot de Edad",
ylab = "Edad", col = "lightblue")
boxplot(datos$Edad[datos$Target == 0], datos$Edad[datos$Target == 1],
main = "Boxplot de Edad por Clase",
names = c("Clase 0", "Clase 1"),
col = c("lightblue", "pink"),
ylab = "Edad")
boxplot(datos[, c("Edad", "Tiempo_Reaccion_1", "Medicion_1")],
main = "Boxplot de Variables",
col = c("lightblue", "pink", "lightgreen"),
names = c("Edad", "Reacción", "Medición 1"),
ylab = "Valores")
View(datos)
# 3. Preparación de los datos
# Convertir la variable Target a factor (necesario para clasificación)
datos$Target <- as.factor(datos$Target)
# Dividir los datos en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(123)
trainIndex <- createDataPartition(datos$Target, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]
test <- datos[-trainIndex, ]
# Escalar las variables numéricas (recomendado para K-NN)
escala <- preProcess(train, method = c("center", "scale"))
train_scaled <- predict(escala, train)
test_scaled <- predict(escala, test)
# 4. Modelo de K-NN
# Entrenar un modelo K-NN con k=5
set.seed(123)
knn_pred <- knn(train = train_scaled[, -which(names(train_scaled) == "Target")],
test = test_scaled[, -which(names(test_scaled) == "Target")],
cl = train_scaled$Target, k = 5)
# 4. Modelo de K-NN
# Entrenar un modelo K-NN con k=5
set.seed(123)
knn_pred <- knn(train = train_scaled[, -which(names(train_scaled) == "Target")],
test = test_scaled[, -which(names(test_scaled) == "Target")],
cl = train_scaled$Target, k = 5)
View(datos)
# 5. Modelo de Regresión Logística
# Entrenar un modelo de regresión logística
logistico <- glm(Target ~ ., data = train, family = "binomial")
# Resumen del modelo
summary(logistico)
# Predicción con regresión logística
logistico_pred <- predict(logistico, newdata = test, type = "response")
logistico_clases <- ifelse(logistico_pred > 0.5, 1, 0)
logistico_clases <- as.factor(logistico_clases)
# Evaluar el modelo de regresión logística
confusion_log <- confusionMatrix(logistico_clases, test$Target)
print(confusion_log)
# Verificar si hay valores NaN o Inf después del escalado
if (any(!is.finite(train_scaled)) || any(!is.finite(test_scaled))) {
stop("Datos escalados contienen valores no finitos (NaN o Inf). Verifique sus datos.")
}
# Cargar librerías necesarias
library(tidyverse)   # Para manipulación de datos
library(caret)       # Para modelos y validación cruzada
library(class)       # Para K-NN
# 1. Lectura del dataset
# Asegúrate de guardar el archivo como 'Alzheimer_dataset.csv' en el mismo directorio que el script.
datos <- read.csv("T2/Alzheimer_dataset.csv", sep = ";")
# Exploración inicial
str(datos)  # Estructura del dataset
summary(datos)  # Resumen estadístico
# 2. Análisis exploratorio (EDA)
# Comprobar distribución de la variable objetivo (Target)
table(datos$Target) #TENEMOS QUE TRABAJAR CON TABLE PORQUE ES UNA VARIABLE CATEGÓRICA
#¿Están balanceadas las categorías?
barplot(table(datos$Target), main = "Distribución de la Variable Target",
xlab = "Clase", ylab = "Frecuencia", col = c("skyblue", "orange"))
# Visualización de correlaciones entre variables numéricas
numericas <- select(datos, where(is.numeric))
correlaciones <- cor(numericas)
corrplot::corrplot(correlaciones, method = "circle", main = "Matriz de Correlación")
# Visualizar la distribución de algunas variables
# Edad por clases de Target
hist(datos$Edad[datos$Target == 0], breaks = 15, col = "lightblue", main = "Distribución de Edad (Clase 0)",
xlab = "Edad", ylab = "Frecuencia")
hist(datos$Edad[datos$Target == 1], breaks = 15, col = "pink", main = "Distribución de Edad (Clase 1)",
xlab = "Edad", ylab = "Frecuencia")
# Boxplot para una variable como ejemplo
boxplot(Edad ~ Target, data = datos, main = "Boxplot de Edad por Clase",
xlab = "Clase", ylab = "Edad", col = c("lightblue", "pink"))
#Otras forma de hacer boxplots
boxplot(datos$Edad, main = "Boxplot de Edad",
ylab = "Edad", col = "lightblue")
boxplot(datos$Edad[datos$Target == 0], datos$Edad[datos$Target == 1],
main = "Boxplot de Edad por Clase",
names = c("Clase 0", "Clase 1"),
col = c("lightblue", "pink"),
ylab = "Edad")
boxplot(datos[, c("Edad", "Tiempo_Reaccion_1", "Medicion_1")],
main = "Boxplot de Variables",
col = c("lightblue", "pink", "lightgreen"),
names = c("Edad", "Tº reacción", "Medición 1"),
ylab = "Valores")
#Visualización avanzada con la librería GGPLOT2
ggplot(datos, aes(x = Edad, fill = as.factor(Target))) +
geom_density(alpha = 0.6) +
labs(title = "Distribución de Edad por Clase", x = "Edad", fill = "Clase")
# 3. Preparación de los datos
# Convertir la variable Target a factor (necesario para clasificación)
datos$Target <- as.factor(datos$Target)
# Dividir los datos en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(123)
trainIndex <- createDataPartition(datos$Target, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]
test <- datos[-trainIndex, ]
# Escalar las variables numéricas (recomendado para K-NN)
escala <- preProcess(train, method = c("center", "scale"))
train_scaled <- predict(escala, train)
test_scaled <- predict(escala, test)
# Verificar si hay valores NaN o Inf después del escalado
if (any(!is.finite(train_scaled)) || any(!is.finite(test_scaled))) {
stop("Datos escalados contienen valores no finitos (NaN o Inf). Verifique sus datos.")
}
# Verificar si hay valores no finitos en los datos escalados
if (any(!apply(train_scaled, 2, is.finite)) || any(!apply(test_scaled, 2, is.finite))) {
stop("Datos escalados contienen valores no finitos (NaN o Inf). Verifique sus datos.")
}
View(train_scaled)
View(test_scaled)
set.seed(123)
knn_pred <- knn(train = train_scaled[, -which(names(train_scaled) == "Target")],
test = test_scaled[, -which(names(test_scaled) == "Target")],
cl = train_scaled$Target, k = 5)
# Cargar librerías necesarias
library(tidyverse)   # Para manipulación de datos
library(caret)       # Para modelos y validación cruzada
library(class)       # Para K-NN
# 1. Lectura del dataset
# Asegúrate de guardar el archivo como 'Alzheimer_dataset.csv' en el mismo directorio que el script.
datos <- read.csv("T2/Alzheimer_dataset.csv", sep = ";")
# Exploración inicial
str(datos)  # Estructura del dataset
summary(datos)  # Resumen estadístico
# 2. Análisis exploratorio (EDA)
# Comprobar distribución de la variable objetivo (Target)
table(datos$Target) #TENEMOS QUE TRABAJAR CON TABLE PORQUE ES UNA VARIABLE CATEGÓRICA
#¿Están balanceadas las categorías?
barplot(table(datos$Target), main = "Distribución de la Variable Target",
xlab = "Clase", ylab = "Frecuencia", col = c("skyblue", "orange"))
# Visualización de correlaciones entre variables numéricas
numericas <- select(datos, where(is.numeric))
correlaciones <- cor(numericas)
corrplot::corrplot(correlaciones, method = "circle", main = "Matriz de Correlación")
# Visualizar la distribución de algunas variables
# Edad por clases de Target
hist(datos$Edad[datos$Target == 0], breaks = 15, col = "lightblue", main = "Distribución de Edad (Clase 0)",
xlab = "Edad", ylab = "Frecuencia")
hist(datos$Edad[datos$Target == 1], breaks = 15, col = "pink", main = "Distribución de Edad (Clase 1)",
xlab = "Edad", ylab = "Frecuencia")
# Boxplot para una variable como ejemplo
boxplot(Edad ~ Target, data = datos, main = "Boxplot de Edad por Clase",
xlab = "Clase", ylab = "Edad", col = c("lightblue", "pink"))
#Otras forma de hacer boxplots
boxplot(datos$Edad, main = "Boxplot de Edad",
ylab = "Edad", col = "lightblue")
boxplot(datos$Edad[datos$Target == 0], datos$Edad[datos$Target == 1],
main = "Boxplot de Edad por Clase",
names = c("Clase 0", "Clase 1"),
col = c("lightblue", "pink"),
ylab = "Edad")
boxplot(datos[, c("Edad", "Tiempo_Reaccion_1", "Medicion_1")],
main = "Boxplot de Variables",
col = c("lightblue", "pink", "lightgreen"),
names = c("Edad", "Tº reacción", "Medición 1"),
ylab = "Valores")
#Visualización avanzada con la librería GGPLOT2
ggplot(datos, aes(x = Edad, fill = as.factor(Target))) +
geom_density(alpha = 0.6) +
labs(title = "Distribución de Edad por Clase", x = "Edad", fill = "Clase")
# 3. Preparación de los datos
# Convertir la variable Target a factor (necesario para clasificación)
datos$Target <- as.factor(datos$Target)
# Dividir los datos en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(123)
trainIndex <- createDataPartition(datos$Target, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]
test <- datos[-trainIndex, ]
# Escalar las variables numéricas (recomendado para K-NN)
escala <- preProcess(train, method = c("center", "scale"))
train_scaled <- predict(escala, train)
test_scaled <- predict(escala, test)
# Cargar librerías necesarias
library(tidyverse)   # Para manipulación de datos
library(caret)       # Para modelos y validación cruzada
library(class)       # Para K-NN
# 1. Lectura del dataset
# Asegúrate de guardar el archivo como 'Alzheimer_dataset.csv' en el mismo directorio que el script.
datos <- read.csv("T2/Alzheimer_dataset.csv", sep = ";")
# Exploración inicial
str(datos)  # Estructura del dataset
summary(datos)  # Resumen estadístico
# 2. Análisis exploratorio (EDA)
# Comprobar distribución de la variable objetivo (Target)
table(datos$Target) #TENEMOS QUE TRABAJAR CON TABLE PORQUE ES UNA VARIABLE CATEGÓRICA
#¿Están balanceadas las categorías?
barplot(table(datos$Target), main = "Distribución de la Variable Target",
xlab = "Clase", ylab = "Frecuencia", col = c("skyblue", "orange"))
# Visualización de correlaciones entre variables numéricas
numericas <- select(datos, where(is.numeric))
correlaciones <- cor(numericas)
corrplot::corrplot(correlaciones, method = "circle", main = "Matriz de Correlación")
# Visualizar la distribución de algunas variables
# Edad por clases de Target
hist(datos$Edad[datos$Target == 0], breaks = 15, col = "lightblue", main = "Distribución de Edad (Clase 0)",
xlab = "Edad", ylab = "Frecuencia")
hist(datos$Edad[datos$Target == 1], breaks = 15, col = "pink", main = "Distribución de Edad (Clase 1)",
xlab = "Edad", ylab = "Frecuencia")
# Boxplot para una variable como ejemplo
boxplot(Edad ~ Target, data = datos, main = "Boxplot de Edad por Clase",
xlab = "Clase", ylab = "Edad", col = c("lightblue", "pink"))
#Otras forma de hacer boxplots
boxplot(datos$Edad, main = "Boxplot de Edad",
ylab = "Edad", col = "lightblue")
boxplot(datos$Edad[datos$Target == 0], datos$Edad[datos$Target == 1],
main = "Boxplot de Edad por Clase",
names = c("Clase 0", "Clase 1"),
col = c("lightblue", "pink"),
ylab = "Edad")
boxplot(datos[, c("Edad", "Tiempo_Reaccion_1", "Medicion_1")],
main = "Boxplot de Variables",
col = c("lightblue", "pink", "lightgreen"),
names = c("Edad", "Tº reacción", "Medición 1"),
ylab = "Valores")
#Visualización avanzada con la librería GGPLOT2
ggplot(datos, aes(x = Edad, fill = as.factor(Target))) +
geom_density(alpha = 0.6) +
labs(title = "Distribución de Edad por Clase", x = "Edad", fill = "Clase")
# 3. Preparación de los datos
# Convertir la variable Target a factor (necesario para clasificación)
datos$Target <- as.factor(datos$Target)
# Dividir los datos en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(123)
trainIndex <- createDataPartition(datos$Target, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]
test <- datos[-trainIndex, ]
# Escalar las variables numéricas (recomendado para K-NN)
escala <- preProcess(train, method = c("center", "scale"))
train_scaled <- predict(escala, train)
test_scaled <- predict(escala, test)
# Eliminar filas con valores NA tras el escalado
train_scaled <- na.omit(train_scaled)
test_scaled <- na.omit(test_scaled)
# 4. Modelo de K-NN
# Entrenar un modelo K-NN con k=5
set.seed(123)
knn_pred <- knn(train = train_scaled[, -which(names(train_scaled) == "Target")],
test = test_scaled[, -which(names(test_scaled) == "Target")],
cl = train_scaled$Target, k = 5)
# Cargar librerías necesarias
library(tidyverse)   # Para manipulación de datos
library(caret)       # Para modelos y validación cruzada
library(class)       # Para K-NN
# 1. Lectura del dataset
# Asegúrate de guardar el archivo como 'Alzheimer_dataset.csv' en el mismo directorio que el script.
datos <- read.csv("T2/Alzheimer_dataset.csv", sep = ";")
# Exploración inicial
str(datos)  # Estructura del dataset
summary(datos)  # Resumen estadístico
# 2. Análisis exploratorio (EDA)
# Comprobar distribución de la variable objetivo (Target)
table(datos$Target) #TENEMOS QUE TRABAJAR CON TABLE PORQUE ES UNA VARIABLE CATEGÓRICA
#¿Están balanceadas las categorías?
barplot(table(datos$Target), main = "Distribución de la Variable Target",
xlab = "Clase", ylab = "Frecuencia", col = c("skyblue", "orange"))
# Visualización de correlaciones entre variables numéricas
numericas <- select(datos, where(is.numeric))
correlaciones <- cor(numericas)
corrplot::corrplot(correlaciones, method = "circle", main = "Matriz de Correlación")
# Visualizar la distribución de algunas variables
# Edad por clases de Target
hist(datos$Edad[datos$Target == 0], breaks = 15, col = "lightblue", main = "Distribución de Edad (Clase 0)",
xlab = "Edad", ylab = "Frecuencia")
hist(datos$Edad[datos$Target == 1], breaks = 15, col = "pink", main = "Distribución de Edad (Clase 1)",
xlab = "Edad", ylab = "Frecuencia")
# Boxplot para una variable como ejemplo
boxplot(Edad ~ Target, data = datos, main = "Boxplot de Edad por Clase",
xlab = "Clase", ylab = "Edad", col = c("lightblue", "pink"))
#Otras forma de hacer boxplots
boxplot(datos$Edad, main = "Boxplot de Edad",
ylab = "Edad", col = "lightblue")
boxplot(datos$Edad[datos$Target == 0], datos$Edad[datos$Target == 1],
main = "Boxplot de Edad por Clase",
names = c("Clase 0", "Clase 1"),
col = c("lightblue", "pink"),
ylab = "Edad")
boxplot(datos[, c("Edad", "Tiempo_Reaccion_1", "Medicion_1")],
main = "Boxplot de Variables",
col = c("lightblue", "pink", "lightgreen"),
names = c("Edad", "Tº reacción", "Medición 1"),
ylab = "Valores")
#Visualización avanzada con la librería GGPLOT2
ggplot(datos, aes(x = Edad, fill = as.factor(Target))) +
geom_density(alpha = 0.6) +
labs(title = "Distribución de Edad por Clase", x = "Edad", fill = "Clase")
# 3. Preparación de los datos
# Convertir la variable Target a factor (necesario para clasificación)
datos$Target <- as.factor(datos$Target)
# Dividir los datos en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(123)
trainIndex <- createDataPartition(datos$Target, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]
test <- datos[-trainIndex, ]
# Escalar las variables numéricas (recomendado para K-NN)
escala <- preProcess(train, method = c("center", "scale"))
train_scaled <- predict(escala, train)
test_scaled <- predict(escala, test)
# Eliminar filas con valores NA tras el escalado
train_scaled <- na.omit(train_scaled)
test_scaled <- na.omit(test_scaled)
# 4. Modelo de K-NN
# Entrenar un modelo K-NN con k=5
set.seed(123)
knn_pred <- knn(train = train_scaled[, -which(names(train_scaled) == "Target")],
test = test_scaled[, -which(names(test_scaled) == "Target")],
cl = train_scaled$Target, k = 5)
# Cargar librerías necesarias
library(tidyverse)   # Para manipulación de datos
library(caret)       # Para modelos y validación cruzada
library(class)       # Para K-NN
# 1. Lectura del dataset
# Asegúrate de guardar el archivo como 'Alzheimer_dataset.csv' en el mismo directorio que el script.
datos <- read.csv("T2/Alzheimer_dataset.csv", sep = ";")
View(datos)
# Cargar librerías necesarias
library(tidyverse)   # Para manipulación de datos
library(caret)       # Para modelos y validación cruzada
library(class)       # Para K-NN
# 1. Lectura del dataset
# Asegúrate de guardar el archivo como 'Alzheimer_dataset.csv' en el mismo directorio que el script.
datos <- read.csv("T2/Alzheimer_dataset.csv", sep = ";")
# Eliminar la columna 'Categoria' asignándole NULL
datos$Categoria <- NULL
# Exploración inicial
str(datos)  # Estructura del dataset
summary(datos)  # Resumen estadístico
# 2. Análisis exploratorio (EDA)
# Comprobar distribución de la variable objetivo (Target)
table(datos$Target) #TENEMOS QUE TRABAJAR CON TABLE PORQUE ES UNA VARIABLE CATEGÓRICA
#¿Están balanceadas las categorías?
barplot(table(datos$Target), main = "Distribución de la Variable Target",
xlab = "Clase", ylab = "Frecuencia", col = c("skyblue", "orange"))
# Visualización de correlaciones entre variables numéricas
numericas <- select(datos, where(is.numeric))
correlaciones <- cor(numericas)
corrplot::corrplot(correlaciones, method = "circle", main = "Matriz de Correlación")
# Visualizar la distribución de algunas variables
# Edad por clases de Target
hist(datos$Edad[datos$Target == 0], breaks = 15, col = "lightblue", main = "Distribución de Edad (Clase 0)",
xlab = "Edad", ylab = "Frecuencia")
hist(datos$Edad[datos$Target == 1], breaks = 15, col = "pink", main = "Distribución de Edad (Clase 1)",
xlab = "Edad", ylab = "Frecuencia")
# Boxplot para una variable como ejemplo
boxplot(Edad ~ Target, data = datos, main = "Boxplot de Edad por Clase",
xlab = "Clase", ylab = "Edad", col = c("lightblue", "pink"))
#Otras forma de hacer boxplots
boxplot(datos$Edad, main = "Boxplot de Edad",
ylab = "Edad", col = "lightblue")
boxplot(datos$Edad[datos$Target == 0], datos$Edad[datos$Target == 1],
main = "Boxplot de Edad por Clase",
names = c("Clase 0", "Clase 1"),
col = c("lightblue", "pink"),
ylab = "Edad")
boxplot(datos[, c("Edad", "Tiempo_Reaccion_1", "Medicion_1")],
main = "Boxplot de Variables",
col = c("lightblue", "pink", "lightgreen"),
names = c("Edad", "Tº reacción", "Medición 1"),
ylab = "Valores")
#Visualización avanzada con la librería GGPLOT2
ggplot(datos, aes(x = Edad, fill = as.factor(Target))) +
geom_density(alpha = 0.6) +
labs(title = "Distribución de Edad por Clase", x = "Edad", fill = "Clase")
# 3. Preparación de los datos
# Convertir la variable Target a factor (necesario para clasificación)
datos$Target <- as.factor(datos$Target)
# Dividir los datos en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(123)
trainIndex <- createDataPartition(datos$Target, p = 0.7, list = FALSE)
train <- datos[trainIndex, ]
test <- datos[-trainIndex, ]
# Escalar las variables numéricas (recomendado para K-NN)
escala <- preProcess(train, method = c("center", "scale"))
train_scaled <- predict(escala, train)
test_scaled <- predict(escala, test)
# Eliminar filas con valores NA tras el escalado
train_scaled <- na.omit(train_scaled)
test_scaled <- na.omit(test_scaled)
# 4. Modelo de K-NN
# Entrenar un modelo K-NN con k=5
set.seed(123)
knn_pred <- knn(train = train_scaled[, -which(names(train_scaled) == "Target")],
test = test_scaled[, -which(names(test_scaled) == "Target")],
cl = train_scaled$Target, k = 5)
# Evaluar el modelo K-NN
confusion_knn <- confusionMatrix(knn_pred, test_scaled$Target)
print(confusion_knn)
# 5. Modelo de Regresión Logística
# Entrenar un modelo de regresión logística
logistico <- glm(Target ~ ., data = train, family = "binomial")
# Resumen del modelo
summary(logistico)
# Predicción con regresión logística
logistico_pred <- predict(logistico, newdata = test, type = "response")
logistico_clases <- ifelse(logistico_pred > 0.5, 1, 0)
logistico_clases <- as.factor(logistico_clases)
# Evaluar el modelo de regresión logística
confusion_log <- confusionMatrix(logistico_clases, test$Target)
print(confusion_log)
# 6. Conclusión
# Comparar métricas clave entre K-NN y regresión logística
cat("K-NN - Precisión:", confusion_knn$overall["Accuracy"], "\n")
cat("Regresión Logística - Precisión:", confusion_log$overall["Accuracy"], "\n")
